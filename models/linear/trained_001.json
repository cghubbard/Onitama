{
  "name": "trained_001",
  "model_type": "linear",
  "created": "2025-11-27T14:30:08.766319",
  "elo": 1051,
  "weights": {
    "material_diff_students": 0.03041375811912816,
    "my_master_alive": 0.0,
    "opp_master_captured": 0.0,
    "master_safety_balance": 1.1095298760656287,
    "legal_moves_diff": -0.12494942898850045,
    "capture_moves_diff": -0.4336254905052517,
    "master_temple_distance_diff": -0.20390725073790616,
    "student_progress_diff": 0.07729165937069753,
    "central_control_diff": 0.16115878813197998,
    "card_mobility_diff": -0.12494942898850045,
    "master_escape_options": 0.17191710329109283
  },
  "bias": 0.22127876543551597,
  "normalization": {
    "means": [
      -0.004106596767147226,
      1.0,
      0.0,
      0.07767584097859327,
      -0.7505460899956313,
      -0.046832678025338574,
      -0.1927479248580166,
      -0.0005606523955147803,
      -0.10476190476190476,
      -0.7505460899956313,
      3.7408475316732197
    ],
    "stds": [
      0.0797588052315655,
      0.0,
      0.0,
      0.5892547497494706,
      3.909715124353593,
      0.5436714569359229,
      1.0886762988529104,
      0.04186447843778236,
      0.6654022834952972,
      3.909715124353593,
      1.5808860978669799
    ],
    "epsilon": 1e-08
  },
  "training": {
    "data_source": "2000 games",
    "num_games": 2000,
    "gamma": 0.97,
    "lambda1": 1.0,
    "lambda2": 1.0,
    "val_loss": 0.6269327805266747,
    "train_loss": 0.6251219077534673,
    "notes": "First trained model on 2000 heuristic self-play games"
  }
}